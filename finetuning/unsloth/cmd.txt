# IN WSL

conda create --name ft \
    python=3.11 \
    pytorch-cuda=12.4 \
    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \
    -y
conda activate ft

pip install unsloth

pip uninstall xformers -y
pip install xformers --index-url https://download.pytorch.org/whl/cu124

# IN WINDOWS:
cd to this directory, then:

python github_repository_scraper.py https://github.com/sadmann7/shadcn-table --process-all-branches --output-file ../repo_datasets/shadcn-table_dataset_no_tests.json --stop-at=70051a0c05d03455dd1ad77062006b95f07b8e46 --no-llm-scan --exclude=test

python github_repository_scraper.py https://github.com/vuejs/core --process-all-branches --stop-at=34989ef7fe846df3d0504d2719149bf42103644c --output-file ../repo_datasets/vue_dataset_no_chores.json --no-llm-scan --exclude=chore

at this point the model output started a lot of chore tasks, but otherwise good commit messages, excluding them on the next entries of the dataset

python github_repository_scraper.py https://github.com/gridsome/gridsome --process-all-branches --stop-at=3090be466361730c4d2cd940a8af4cb562f05738 --output-file ../repo_datasets/gridsome_dataset_no_chores.json --no-llm-scan --exclude=chore

python github_repository_scraper.py https://github.com/twbs/bootstrap --process-all-branches --stop-at=cb40a2ee8c88efdec0c35adf173cc96ba25db21e --output-file ../repo_datasets/bootstrap_dataset_no_chores_and_tests.json --no-llm-scan --exclude=chore,test

--stats-only can be added to analyze repos to modify the script to be more efficient
--no-llm-scan to go FAST (might just be the optimal way to add commits to the dataset)

[ADD THE INSTRUCTIONS HERE TO INSTALL REQUIREMENTS FOR RUNNING THE SCRIPTS]

python combine_repo_datasets.py

run in WSL/linux:
python unsloth-cli.py --model_name "google/gemma-3-1b-it" --max_steps 1600 --per_device_train_batch_size 2 --load_in_4bit --save_model --save_path "testing/data-set-diffchecker-5k-max-1028tok-commits-reduced_chores-v7" --save_method "lora" --max_seq_length 2048

back to windows (if you are on it):
python ../../../llama.cpp/convert_hf_to_gguf.py "../../../coding_tools/finetuning/unsloth/testing/data-set-diffchecker-5k-max-1028tok-commits-reduced_chores-v7" --outfile ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf

# Testing regular, non tuned Gemma 1B
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt_in_dataset.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt1.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt2.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt3.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt4.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt5.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt6.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt7.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt8.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt9.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt10.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt11.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt12.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt13.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt14.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt15.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt16.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt17.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt18.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt19.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/gemma-3-1b-it-Q4_K_M.gguf -f ../prompt_testing/prompt20.txt --temp 0

# Testing the new model
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt_in_dataset.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt1.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt2.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt3.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt4.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt5.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt6.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt7.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt8.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt9.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt10.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt11.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt12.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt13.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt14.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt15.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt16.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt17.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt18.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt19.txt --temp 0
../../../llama.cpp/build/bin/Release/llama-cli -m ../../../models/diffchecker-5k-max-1028tok-commits-reduced_chores-v7.gguf -f ../prompt_testing/prompt20.txt --temp 0
